{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting rooftop available surface for installing PV modules in aerial images using Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot  as plt\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "\n",
    "from process_data.data_noara_loader import *\n",
    "from model.unet import *\n",
    "from loss.loss import *\n",
    "from process_data.data_loader import *\n",
    "from process_data.data_noara_loader import *\n",
    "from hyperparameters.select_param import *\n",
    "from process_data.import_test import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Data Set\n",
    "First we load the data set that we will use for training. Each sample is an image with its mask (label). An image is represented as a 3x250x250 array with each of the 3 color chanel being 250x250 pixels. The asssociated mask is a 250x250 array, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path_image = 'data/image'\n",
    "folder_path_mask  = 'data/mask'\n",
    "folder_path_noara  = 'data/noARA'\n",
    "\n",
    "#load dataset\n",
    "train_dataset = DataLoaderSegmentation(folder_path_image,folder_path_mask)\n",
    "noara_dataset = DataLoaderNoARA(folder_path_noara)\n",
    "\n",
    "#combine two datasets\n",
    "train_loader = DataLoader(ConcatDataset([train_dataset,noara_dataset]),batch_size=5, shuffle=True ,num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiate the model\n",
    "In this report, we will use the Unet model presented in medical image segmentation, and in the previous papers of the Professor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "UNet(\n  (inc): inconv(\n    (conv): double_conv(\n      (conv): Sequential(\n        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (5): ReLU(inplace=True)\n      )\n    )\n  )\n  (down1): down(\n    (mpconv): Sequential(\n      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (1): double_conv(\n        (conv): Sequential(\n          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): ReLU(inplace=True)\n        )\n      )\n    )\n  )\n  (down2): down(\n    (mpconv): Sequential(\n      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (1): double_conv(\n        (conv): Sequential(\n          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): ReLU(inplace=True)\n        )\n      )\n    )\n  )\n  (down3): down(\n    (mpconv): Sequential(\n      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (1): double_conv(\n        (conv): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): ReLU(inplace=True)\n        )\n      )\n    )\n  )\n  (down4): down(\n    (mpconv): Sequential(\n      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (1): double_conv(\n        (conv): Sequential(\n          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): ReLU(inplace=True)\n        )\n      )\n    )\n  )\n  (up1): up(\n    (up): ConvTranspose2d(512, 512, kernel_size=(2, 2), stride=(2, 2))\n    (conv): double_conv(\n      (conv): Sequential(\n        (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (5): ReLU(inplace=True)\n      )\n    )\n  )\n  (up2): up(\n    (up): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n    (conv): double_conv(\n      (conv): Sequential(\n        (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (5): ReLU(inplace=True)\n      )\n    )\n  )\n  (up3): up(\n    (up): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2))\n    (conv): double_conv(\n      (conv): Sequential(\n        (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (5): ReLU(inplace=True)\n      )\n    )\n  )\n  (up4): up(\n    (up): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n    (conv): double_conv(\n      (conv): Sequential(\n        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (5): ReLU(inplace=True)\n      )\n    )\n  )\n  (outc): outconv(\n    (conv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (activation): Sigmoid()\n)\n"
     ]
    }
   ],
   "source": [
    "model = UNet(3,1,False).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "model = UNet(3,1,False).to(device)\n",
    "loss_function = torch.nn.BCEWithLogitsLoss(weight=torch.FloatTensor([6]).cuda())\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "trained_model = training_model(train_loader,loss_function,optimizer,model,num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = trained_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model/trained_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'model/'+input('Name of the model file:')\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "source": [
    "# Training with learning rate decay"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 500\n",
    "loss_function = torch.nn.BCEWithLogitsLoss(weight=torch.FloatTensor([5]).cuda())\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.05)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 50, gamma=0.5, last_epoch=-1, verbose=False)\n",
    "\n",
    "trained_model = training_model(train_loader,loss_function,optimizer,model,num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = torch.nn.BCEWithLogitsLoss()\n",
    "num_epochs = 2\n",
    "lr = 0.01\n",
    "\n",
    "iou_, acc_ = cross_validation(train_dataset, loss_function, input_model, num_epochs, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning the hyper parameters\n",
    "We may do a grid search on the learning rates with cross validation to find the best learning_rate. For now the used metric is iou."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lr_candidates = np.logspace(-1,-2,3)\n",
    "num_epochs = 200\n",
    "loss_function = torch.nn.BCEWithLogitsLoss(pos_weight=torch.FloatTensor([6]).cuda())\n",
    "\n",
    "input_model = UNet(3,1,False).to(device)\n",
    "\n",
    "best_lr, best_model, best_iou = select_hyper_param(train_dataset,loss_function,input_model,num_epochs,lr_candidates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model.state_dict(), 'model/best_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lr, best_iou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display a image with its mask"
   ]
  },
  {
   "source": [
    "fig = plt.figure()\n",
    "fig.set_size_inches(12, 7, forward=True)\n",
    "\n",
    "ax1 = fig.add_subplot(1,3,1)\n",
    "ax1.title.set_text('Input Image')\n",
    "ax2 = fig.add_subplot(1,3,2)\n",
    "ax2.title.set_text('Expected Label')\n",
    "ax3 = fig.add_subplot(1,3,3)\n",
    "ax3.title.set_text('Predicted Label')\n",
    "\n",
    "acc = 0\n",
    "\n",
    "index_random_sample = int(np.random.random()*len(train_loader.dataset))\n",
    "(x,y) = train_loader.dataset[index_random_sample]\n",
    "ax1.imshow(np.transpose(x.numpy(),(1,2,0)))\n",
    "\n",
    "ax2.imshow(y)\n",
    "\n",
    "ypred = torch.squeeze(model(torch.unsqueeze(x,0).cuda())).cpu().detach().numpy()\n",
    "ax3.imshow(np.around(ypred))\n",
    "np.around(iou(np.around(ypred),y.numpy()),4),accuracy(np.around(ypred),y.numpy())\n",
    "acc = np.around(iou(np.around(ypred),y.numpy()),4)\n",
    "plt.show()\n",
    "print(acc,accuracy(np.around(ypred),y.numpy()))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "## Display an unseen image"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_and_show(model,'test.png') # Note that 'test.png' should be located in the root of the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}